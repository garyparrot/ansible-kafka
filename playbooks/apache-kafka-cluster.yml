---
- name: shutdown loading
  import_playbook: ./stop-loading.yml

- hosts: cluster_hosts
  gather_facts: true

  vars_files:
    - ../common-variables.yml
    - ../common-configs.yml

  vars:
    TARGET_GROUP: cluster_hosts
    JMX_CONFIG_FILE: "{{ GIT_REPO_BASE_DEST }}/kafka-jmx-exporter.yml"
    USE_CONFLUENT_BROKER: "{{ CONFLUENT_BROKER | default('false') | bool }}"

  pre_tasks:
    - name: ensure base dir exists
      ansible.builtin.file:
        path: "{{ GIT_REPO_BASE_DEST }}"
        state: directory 

    - name: prepare JMX exporter config file
      ansible.builtin.template:
        src: ../templates/kafka-jmx-exporter.yml
        dest: "{{ JMX_CONFIG_FILE }}"

  tasks:
    - name: remove old cluster instance if one exists
      import_tasks: ../tasks/remove-cluster.yml

    - name: ensure data directories exists
      ansible.builtin.file:
        path: "{{ item }}"
        state: directory 
      loop: "{{ DATA_FOLDERS.split(',') }}"
      when: "DATA_FOLDERS is defined"

    - name: ensure astraea project exists and move to the newest progress
      ansible.builtin.git:
        repo: "{{ GIT_REPO }}"
        dest: "{{ GIT_REPO_DEST }}"
        update: yes
        force: yes
        version: "{{ GIT_REPO_BRANCH }}"

    - name: prepare one for the main astraea
      ansible.builtin.git:
        repo: "https://github.com/skiptests/astraea.git"
        dest: "{{ GIT_REPO_MAIN_DEST }}"
        update: yes
        force: yes

    - name: launch Zookeeper on specific host (execute script)
      ansible.builtin.command: "{{ ZOOKEEPER_SCRIPT }}"
      environment:
        ZOOKEEPER_PORT: "{{ ZK_PORT }}"
      register: output_zookeeper_script
      when: inventory_hostname == groups[TARGET_GROUP][0]
    
    - name: launch Kafka on all hosts (execute script)
      ansible.builtin.command: 
        argv:
          - "{{ KAFKA_SCRIPT }}"
          - "broker.id={{ BROKER_ID }}"
          - "zookeeper.connect={{ groups[TARGET_GROUP][0] }}:{{ ZK_PORT }}"
          - "num.replica.fetchers=6"
          - "num.io.threads=24"
          - "num.network.threads=24"
          - "replica.socket.receive.buffer.bytes=-1"
          # Try to deal with the high per partition consume issue
          - "message.max.bytes=100000000"
          - "socket.send.buffer.bytes=800000"
          - "socket.receive.buffer.bytes=800000"
          - "socket.request.max.bytes=804857600"
          # - "queued.max.requests=100000"
          # Increase the receive buffer
          # - "replica.socket.receive.buffer.bytes=1048576"
          # For 10GbE connection
          # - "socket.send.buffer.bytes=16777216"
          # - "socket.receive.buffer.bytes=16777216"
          # - "background.threads=20"
          # - "log.cleaner.threads=20"
          # - "compression.type=lz4"
          - "{{ CONFLUENT_BALANCER_HEAL_TRIGGER if USE_CONFLUENT_BROKER else '' }}"
      environment:
        # VERSION: "trunk"
        BROKER_PORT: "{{ BROKER_PORT }}"
        EXPORTER_PORT: "{{ EXPORTER_PORT }}"
        BROKER_JMX_PORT: "{{ JMX_PORT }}"
        JMX_CONFIG_FILE: "{{ JMX_CONFIG_FILE | default('') }}"
        DATA_FOLDERS: "{{ DATA_FOLDERS | default(None) }}"
        CONFLUENT_BROKER: "{{ USE_CONFLUENT_BROKER | default('false') }}"
        HEAP_OPTS: "-Xmx8G"

      register: output_kafka_script

    - name: debug zookeeper script
      ansible.builtin.debug:
        var: output_zookeeper_script
      when: DEBUG_MESSAGE

    - name: debug kafka script
      ansible.builtin.debug:
        var: output_kafka_script
      when: DEBUG_MESSAGE
    
- name: import the friendly print-info playbook
  import_playbook: ./print-info.yml
